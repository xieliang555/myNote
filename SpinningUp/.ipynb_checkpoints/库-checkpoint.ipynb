{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-06T01:14:29.769189Z",
     "start_time": "2019-07-06T01:14:29.456179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "离散动作：CartPole-v0\n",
      "maximum episode length:  200\n",
      "环境对象：  <TimeLimit<CartPoleEnv<CartPole-v0>>>\n",
      "动作对象：  Discrete(2)\n",
      "状态对象：  Box(4,)\n",
      "动作维度：  2\n",
      "状态维度：  (4,)\n",
      "s_0：  [-0.02897853 -0.04021798  0.00864633 -0.04581529]\n",
      "a_0： 1\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "# # gym\n",
    "# # 离散动作：CartPole-v0；连续动作：CarRacing-v0；依赖于Atari库:MountainCar-v0；依赖于MuJoCo库:Hopper-v2\n",
    "# # 所有环境介绍： http://gym.openai.com/envs/#classic_control\n",
    "# # print(\"所有环境： \",gym.envs.registry.all())\n",
    "# print(\"离散动作：CartPole-v0\")\n",
    "# env=gym.make('CartPole-v0')\n",
    "# print(\"maximum episode length: \",env.spec.max_episode_steps)\n",
    "# print(\"环境对象： \",env)\n",
    "# print(\"动作对象： \",env.action_space)\n",
    "# print(\"状态对象： \",env.observation_space)\n",
    "# # 注意离散动作的维度不是指n个变量，而是一个变量的不同取值，如汽车的方向，可以向左或向右或不动，则n=3，注意与连续动作区分\n",
    "# print(\"动作维度： \",env.action_space.n)\n",
    "# # print(env.action_space.shape)\n",
    "# print(\"状态维度： \",env.observation_space.shape)\n",
    "# obs=env.reset()\n",
    "# print(\"s_0： \",obs)\n",
    "# action=env.action_space.sample()\n",
    "# print(\"a_0：\",action)\n",
    "# obs,reward,done,_=env.step(action)\n",
    "# print(\"step 1：  s_1：\",obs,\" r_1：\",reward,\" 是否结束：\",done)\n",
    "# # # 运行时不能全屏\n",
    "# # for i in range(100):\n",
    "# #         env.render()\n",
    "# #         _,r,done,_=env.step(env.action_space.sample())\n",
    "# #         print(i,r)\n",
    "# #         if(done):\n",
    "# #             print('done: ',i,r)\n",
    "# #             env.reset() \n",
    "# # env.close()\n",
    "\n",
    "\n",
    "# print(\"=========================================\")\n",
    "# print(\"连续动作：Pendulum-v0\")\n",
    "# env=gym.make('HalfCheetah-v2')\n",
    "# print(\"动作对象： \",env.action_space)\n",
    "# print(\"状态对象： \",env.observation_space)\n",
    "# # 连续动作维度是指有n个动作变量，high是n维一个数组记录每一个变量的最高值，low同理\n",
    "# print(\"动作维度： \",env.action_space.shape)\n",
    "# print(\"连续动作最大值： \",env.action_space.high)\n",
    "# print(\"连续动作最小值： \",env.action_space.low)\n",
    "# print(\"状态维度： \",env.observation_space.shape)\n",
    "# print('0维动作最大值：',env.action_space.high[0])\n",
    "# print(\"maximum episode length: \",env.spec.max_episode_steps)\n",
    "# # obs=env.reset()\n",
    "# # print(\"s_0： \",obs)\n",
    "# # action=env.action_space.sample()\n",
    "# # print(\"a_0：\",action)\n",
    "# # # obs,reward,done,_=env.step(action)\n",
    "# # # print(\"step 1：  s_1：\",obs,\" r_1：\",reward,\" 是否结束：\",done)\n",
    "# # # 运行时不能全屏\n",
    "# # for i in range(2000):\n",
    "# #         env.render()\n",
    "# #         o,r,done,_=env.step(env.action_space.sample())\n",
    "# #         print(i,r)\n",
    "# #         if(done):\n",
    "# #             print('done: ',i,r)\n",
    "# #             env.reset() \n",
    "# # env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spinup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T03:04:50.992267Z",
     "start_time": "2019-06-23T03:04:49.801943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1mLogging data to /tmp/experiments/1561259090/progress.txt\u001b[0m\n",
      "\u001b[36;1mSaving config:\n",
      "\u001b[0m\n",
      "{\n",
      "    \"exp_name\":\t\"vpg\"\n",
      "}\n",
      "\u001b[32;1ma = 10, b = 20\u001b[0m\n",
      "WARNING:tensorflow:From /Users/xieliang/spinningup/spinup/utils/logx.py:226: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\n",
      "WARNING:tensorflow:From /Users/xieliang/anaconda3/envs/rl/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /tmp/experiments/1561259090/simple_save/saved_model.pb\n",
      "-------------------------------------\n",
      "|     Averagekey1 |              10 |\n",
      "|         Stdkey1 |               0 |\n",
      "|         Maxkey1 |              10 |\n",
      "|         Minkey1 |              10 |\n",
      "|            key2 |              30 |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from spinup.utils.logx import EpochLogger\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "\n",
    "# logger 调试（临时变量保存在内置容器），保存模型，超参数（保存在指定路径）\n",
    "env=gym.make(\"CartPole-v0\")\n",
    "\n",
    "tf.reset_default_graph()\n",
    "x=tf.placeholder(dtype=tf.float32)\n",
    "y1=tf.constant([1,2])\n",
    "y2=tf.constant([4,5])\n",
    "sess=tf.Session()\n",
    "\n",
    "logger_kwargs=dict(exp_name=\"vpg\")\n",
    "# print(logger_kwargs)\n",
    "# 定义对象，打印保存路径（以下所有需要保存的均保存在该路径中）,\n",
    "# logger_kwargs传入的参数将通过save_config保存在路径中\n",
    "logger = EpochLogger(**logger_kwargs)\n",
    "# 将dict()传入的参数和上述logger_kwargs传入的参数保存在路径中，\n",
    "# 并打印，注意传入的是dict不是**dict,注意两者区别\n",
    "# logger.save_config(locals())\n",
    "logger.save_config(dict())\n",
    "# 打印信息\n",
    "a=(10,20)\n",
    "logger.log(\"a = %d, b = %d\"%a)\n",
    "# 保存tensorflow结构图,仅保存训练好模型后测试时需要计算的重要结点，而不是保存整张图\n",
    "# 设置需要保存的结点\n",
    "logger.setup_tf_saver(sess,inputs={'x':x},outputs={'y1':y1,'y2':y2})\n",
    "# #保存已设置需要保存的结点\n",
    "# logger._tf_simple_save()\n",
    "# 除了保存已设置需要保存的结点，还会保存传入的dict，通常是环境对象\n",
    "logger.save_state({'env':env})\n",
    "# 保存dict类型在logger内置容器中，如果容器内不存在该dict的key，则在该容器中追加\n",
    "logger.store(key1=10)\n",
    "# 以表格形式打印store内置容器中的dict，通常打印模型的metrics用于训练评估模型，清空容器\n",
    "# logger.log_tabular('key1',average_only==True)\n",
    "logger.log_tabular('key1',with_min_and_max=True)\n",
    "# 如果没有store，则在参数中需要传入val：如30\n",
    "logger.log_tabular('key2',30)\n",
    "logger.dump_tabular()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 常见错误"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tensor与np array弄错，一般训练样本和debug信息是numpy array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rl]",
   "language": "python",
   "name": "conda-env-rl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "609px",
    "left": "447px",
    "top": "237px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
