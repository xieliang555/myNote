{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-04T14:04:23.117805Z",
     "start_time": "2019-06-04T13:59:14.462121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1mLogging data to /tmp/experiments/1559656756/progress.txt\u001b[0m\n",
      "\u001b[36;1mSaving config:\n",
      "\u001b[0m\n",
      "{\n",
      "    \"ac_kwargs\":\t{},\n",
      "    \"act_noise\":\t0.1,\n",
      "    \"batch_size\":\t100,\n",
      "    \"env_fn\":\t\"<function <lambda> at 0x131bf3f28>\",\n",
      "    \"epochs\":\t10,\n",
      "    \"exp_name\":\t\"td3\",\n",
      "    \"gamma\":\t0.99,\n",
      "    \"logger\":\t{\n",
      "        \"<spinup.utils.logx.EpochLogger object at 0x13388eb00>\":\t{\n",
      "            \"epoch_dict\":\t{},\n",
      "            \"exp_name\":\t\"td3\",\n",
      "            \"first_row\":\ttrue,\n",
      "            \"log_current_row\":\t{},\n",
      "            \"log_headers\":\t[],\n",
      "            \"output_dir\":\t\"/tmp/experiments/1559656756\",\n",
      "            \"output_file\":\t{\n",
      "                \"<_io.TextIOWrapper name='/tmp/experiments/1559656756/progress.txt' mode='w' encoding='UTF-8'>\":\t{\n",
      "                    \"mode\":\t\"w\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"logger_kwargs\":\t{\n",
      "        \"exp_name\":\t\"td3\"\n",
      "    },\n",
      "    \"max_ep_len\":\t1000,\n",
      "    \"noise_clip\":\t0.5,\n",
      "    \"pi_lr\":\t0.001,\n",
      "    \"policy_delay\":\t2,\n",
      "    \"polyak\":\t0.995,\n",
      "    \"q_lr\":\t0.001,\n",
      "    \"replay_size\":\t1000000,\n",
      "    \"start_steps\":\t10000,\n",
      "    \"steps_per_epoch\":\t5000,\n",
      "    \"target_noise\":\t0.2\n",
      "}\n",
      "\n",
      "Number of parameters: pi 129306, q1: 130201, q2: 130201, total: 389708\n",
      "\n",
      "---------------------------------------\n",
      "|             Epoch |               1 |\n",
      "|      AverageEpRet |            -288 |\n",
      "|          StdEpRet |              92 |\n",
      "|          MaxEpRet |            -198 |\n",
      "|          MinEpRet |            -462 |\n",
      "|  AverageTestEpRet |            -678 |\n",
      "|      StdTestEpRet |            64.7 |\n",
      "|      MaxTestEpRet |            -598 |\n",
      "|      MinTestEpRet |            -733 |\n",
      "|             EpLen |           1e+03 |\n",
      "|         TestEpLen |           1e+03 |\n",
      "| TotalEnvInteracts |           5e+03 |\n",
      "|     AverageQ1Vals |       -6.69e+07 |\n",
      "|         StdQ1Vals |        7.53e+07 |\n",
      "|         MaxQ1Vals |           0.934 |\n",
      "|         MinQ1Vals |       -6.08e+08 |\n",
      "|     AverageQ2Vals |       -7.31e+07 |\n",
      "|         StdQ2Vals |         8.2e+07 |\n",
      "|         MaxQ2Vals |           0.942 |\n",
      "|         MinQ2Vals |       -6.53e+08 |\n",
      "|            LossPi |        6.28e+07 |\n",
      "|             LossQ |        -1.4e+08 |\n",
      "|              Time |            28.7 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "|             Epoch |               2 |\n",
      "|      AverageEpRet |            -228 |\n",
      "|          StdEpRet |            36.5 |\n",
      "|          MaxEpRet |            -176 |\n",
      "|          MinEpRet |            -285 |\n",
      "|  AverageTestEpRet |            -589 |\n",
      "|      StdTestEpRet |           0.941 |\n",
      "|      MaxTestEpRet |            -588 |\n",
      "|      MinTestEpRet |            -591 |\n",
      "|             EpLen |           1e+03 |\n",
      "|         TestEpLen |           1e+03 |\n",
      "| TotalEnvInteracts |           1e+04 |\n",
      "|     AverageQ1Vals |       -6.68e+08 |\n",
      "|         StdQ1Vals |        3.87e+08 |\n",
      "|         MaxQ1Vals |       -1.82e+07 |\n",
      "|         MinQ1Vals |       -3.41e+09 |\n",
      "|     AverageQ2Vals |        -7.3e+08 |\n",
      "|         StdQ2Vals |        4.19e+08 |\n",
      "|         MaxQ2Vals |       -1.94e+07 |\n",
      "|         MinQ2Vals |       -3.68e+09 |\n",
      "|            LossPi |        6.32e+08 |\n",
      "|             LossQ |        -1.4e+09 |\n",
      "|              Time |            59.3 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "|             Epoch |               3 |\n",
      "|      AverageEpRet |            -503 |\n",
      "|          StdEpRet |            39.1 |\n",
      "|          MaxEpRet |            -456 |\n",
      "|          MinEpRet |            -553 |\n",
      "|  AverageTestEpRet |            -599 |\n",
      "|      StdTestEpRet |           0.521 |\n",
      "|      MaxTestEpRet |            -598 |\n",
      "|      MinTestEpRet |            -600 |\n",
      "|             EpLen |           1e+03 |\n",
      "|         TestEpLen |           1e+03 |\n",
      "| TotalEnvInteracts |         1.5e+04 |\n",
      "|     AverageQ1Vals |       -2.02e+09 |\n",
      "|         StdQ1Vals |        9.85e+08 |\n",
      "|         MaxQ1Vals |       -1.03e+08 |\n",
      "|         MinQ1Vals |       -8.54e+09 |\n",
      "|     AverageQ2Vals |        -2.2e+09 |\n",
      "|         StdQ2Vals |        1.07e+09 |\n",
      "|         MaxQ2Vals |       -1.17e+08 |\n",
      "|         MinQ2Vals |        -9.2e+09 |\n",
      "|            LossPi |        2.06e+09 |\n",
      "|             LossQ |       -4.21e+09 |\n",
      "|              Time |            93.3 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "|             Epoch |               4 |\n",
      "|      AverageEpRet |            -548 |\n",
      "|          StdEpRet |            9.81 |\n",
      "|          MaxEpRet |            -529 |\n",
      "|          MinEpRet |            -554 |\n",
      "|  AverageTestEpRet |            -599 |\n",
      "|      StdTestEpRet |           0.914 |\n",
      "|      MaxTestEpRet |            -598 |\n",
      "|      MinTestEpRet |            -601 |\n",
      "|             EpLen |           1e+03 |\n",
      "|         TestEpLen |           1e+03 |\n",
      "| TotalEnvInteracts |           2e+04 |\n",
      "|     AverageQ1Vals |       -4.28e+09 |\n",
      "|         StdQ1Vals |        1.94e+09 |\n",
      "|         MaxQ1Vals |       -9.94e+07 |\n",
      "|         MinQ1Vals |       -1.83e+10 |\n",
      "|     AverageQ2Vals |       -4.64e+09 |\n",
      "|         StdQ2Vals |         2.1e+09 |\n",
      "|         MaxQ2Vals |       -1.19e+08 |\n",
      "|         MinQ2Vals |       -1.96e+10 |\n",
      "|            LossPi |        4.62e+09 |\n",
      "|             LossQ |       -8.92e+09 |\n",
      "|              Time |             126 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "|             Epoch |               5 |\n",
      "|      AverageEpRet |            -551 |\n",
      "|          StdEpRet |            1.04 |\n",
      "|          MaxEpRet |            -550 |\n",
      "|          MinEpRet |            -553 |\n",
      "|  AverageTestEpRet |            -598 |\n",
      "|      StdTestEpRet |           0.961 |\n",
      "|      MaxTestEpRet |            -597 |\n",
      "|      MinTestEpRet |            -600 |\n",
      "|             EpLen |           1e+03 |\n",
      "|         TestEpLen |           1e+03 |\n",
      "| TotalEnvInteracts |         2.5e+04 |\n",
      "|     AverageQ1Vals |       -8.14e+09 |\n",
      "|         StdQ1Vals |         3.1e+09 |\n",
      "|         MaxQ1Vals |       -1.52e+07 |\n",
      "|         MinQ1Vals |       -3.21e+10 |\n",
      "|     AverageQ2Vals |       -8.84e+09 |\n",
      "|         StdQ2Vals |        3.35e+09 |\n",
      "|         MaxQ2Vals |       -2.56e+07 |\n",
      "|         MinQ2Vals |       -3.43e+10 |\n",
      "|            LossPi |        8.92e+09 |\n",
      "|             LossQ |        -1.7e+10 |\n",
      "|              Time |             157 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "|             Epoch |               6 |\n",
      "|      AverageEpRet |            -552 |\n",
      "|          StdEpRet |             2.6 |\n",
      "|          MaxEpRet |            -547 |\n",
      "|          MinEpRet |            -555 |\n",
      "|  AverageTestEpRet |            -600 |\n",
      "|      StdTestEpRet |           0.453 |\n",
      "|      MaxTestEpRet |            -599 |\n",
      "|      MinTestEpRet |            -601 |\n",
      "|             EpLen |           1e+03 |\n",
      "|         TestEpLen |           1e+03 |\n",
      "| TotalEnvInteracts |           3e+04 |\n",
      "|     AverageQ1Vals |       -1.41e+10 |\n",
      "|         StdQ1Vals |        4.48e+09 |\n",
      "|         MaxQ1Vals |       -1.26e+06 |\n",
      "|         MinQ1Vals |        -5.1e+10 |\n",
      "|     AverageQ2Vals |       -1.53e+10 |\n",
      "|         StdQ2Vals |        4.83e+09 |\n",
      "|         MaxQ2Vals |       -6.17e+06 |\n",
      "|         MinQ2Vals |       -5.51e+10 |\n",
      "|            LossPi |        1.54e+10 |\n",
      "|             LossQ |       -2.93e+10 |\n",
      "|              Time |             189 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "|             Epoch |               7 |\n",
      "|      AverageEpRet |            -552 |\n",
      "|          StdEpRet |             1.1 |\n",
      "|          MaxEpRet |            -550 |\n",
      "|          MinEpRet |            -553 |\n",
      "|  AverageTestEpRet |            -599 |\n",
      "|      StdTestEpRet |           0.639 |\n",
      "|      MaxTestEpRet |            -598 |\n",
      "|      MinTestEpRet |            -600 |\n",
      "|             EpLen |           1e+03 |\n",
      "|         TestEpLen |           1e+03 |\n",
      "| TotalEnvInteracts |         3.5e+04 |\n",
      "|     AverageQ1Vals |       -2.24e+10 |\n",
      "|         StdQ1Vals |        6.17e+09 |\n",
      "|         MaxQ1Vals |       -1.97e+05 |\n",
      "|         MinQ1Vals |       -7.85e+10 |\n",
      "|     AverageQ2Vals |       -2.44e+10 |\n",
      "|         StdQ2Vals |        6.65e+09 |\n",
      "|         MaxQ2Vals |        -2.4e+05 |\n",
      "|         MinQ2Vals |       -8.18e+10 |\n",
      "|            LossPi |        2.45e+10 |\n",
      "|             LossQ |       -4.69e+10 |\n",
      "|              Time |             219 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "|             Epoch |               8 |\n",
      "|      AverageEpRet |            -552 |\n",
      "|          StdEpRet |           0.992 |\n",
      "|          MaxEpRet |            -551 |\n",
      "|          MinEpRet |            -554 |\n",
      "|  AverageTestEpRet |            -600 |\n",
      "|      StdTestEpRet |           0.484 |\n",
      "|      MaxTestEpRet |            -599 |\n",
      "|      MinTestEpRet |            -601 |\n",
      "|             EpLen |           1e+03 |\n",
      "|         TestEpLen |           1e+03 |\n",
      "| TotalEnvInteracts |           4e+04 |\n",
      "|     AverageQ1Vals |       -3.38e+10 |\n",
      "|         StdQ1Vals |        8.14e+09 |\n",
      "|         MaxQ1Vals |       -2.41e+05 |\n",
      "|         MinQ1Vals |        -1.1e+11 |\n",
      "|     AverageQ2Vals |       -3.68e+10 |\n",
      "|         StdQ2Vals |        8.76e+09 |\n",
      "|         MaxQ2Vals |       -2.63e+05 |\n",
      "|         MinQ2Vals |       -1.15e+11 |\n",
      "|            LossPi |        3.68e+10 |\n",
      "|             LossQ |       -7.06e+10 |\n",
      "|              Time |             250 |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|             Epoch |               9 |\n",
      "|      AverageEpRet |            -555 |\n",
      "|          StdEpRet |            1.06 |\n",
      "|          MaxEpRet |            -553 |\n",
      "|          MinEpRet |            -556 |\n",
      "|  AverageTestEpRet |            -600 |\n",
      "|      StdTestEpRet |           0.651 |\n",
      "|      MaxTestEpRet |            -599 |\n",
      "|      MinTestEpRet |            -602 |\n",
      "|             EpLen |           1e+03 |\n",
      "|         TestEpLen |           1e+03 |\n",
      "| TotalEnvInteracts |         4.5e+04 |\n",
      "|     AverageQ1Vals |       -4.84e+10 |\n",
      "|         StdQ1Vals |        1.05e+10 |\n",
      "|         MaxQ1Vals |       -3.28e+05 |\n",
      "|         MinQ1Vals |       -1.51e+11 |\n",
      "|     AverageQ2Vals |       -5.27e+10 |\n",
      "|         StdQ2Vals |        1.13e+10 |\n",
      "|         MaxQ2Vals |       -3.58e+05 |\n",
      "|         MinQ2Vals |       -1.58e+11 |\n",
      "|            LossPi |        5.23e+10 |\n",
      "|             LossQ |       -1.01e+11 |\n",
      "|              Time |             281 |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import time\n",
    "from spinup.utils.logx import EpochLogger\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self,obs_dim,act_dim,size):\n",
    "        self.obs1_buf=np.zeros((size,obs_dim),dtype=np.float32)\n",
    "        self.obs2_buf=np.zeros((size,obs_dim),dtype=np.float32)\n",
    "        self.acts_buf=np.zeros((size,act_dim),dtype=np.float32)\n",
    "        self.rews_buf=np.zeros(size,dtype=np.float32)\n",
    "        self.done_buf=np.zeros(size,dtype=np.float32)\n",
    "        self.ptr,self.size,self.max_size=0,0,size\n",
    "        \n",
    "    # simple FIFO\n",
    "    def store(self,obs,act,rew,next_obs,done):\n",
    "        self.obs1_buf[self.ptr]=obs\n",
    "        self.acts_buf[self.ptr]=act\n",
    "        self.rews_buf[self.ptr]=rew\n",
    "        self.obs2_buf[self.ptr]=next_obs\n",
    "        self.done_buf[self.ptr]=done\n",
    "        self.ptr=(self.ptr+1)%self.max_size\n",
    "        self.size=min(self.size+1,self.max_size)\n",
    "        \n",
    "    def sample_batch(self,batch_size=32):\n",
    "        idx=np.random.randint(0,self.size,size=batch_size)\n",
    "        return dict(obs1=self.obs1_buf[idx],\n",
    "                    obs2=self.obs2_buf[idx],\n",
    "                    acts=self.acts_buf[idx],\n",
    "                    rews=self.rews_buf[idx],\n",
    "                    done=self.done_buf[idx])\n",
    " \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "td3: twin delayed DDPG\n",
    "\n",
    "\"\"\"\n",
    "def mlp(x,hidden_sizes=[32,],activation=tf.tanh,output_activation=None):\n",
    "    for i in hidden_sizes[:-1]:\n",
    "        x=tf.layers.dense(x,units=i,activation=activation)\n",
    "    return tf.layers.dense(x,units=hidden_sizes[-1],activation=output_activation)\n",
    "\n",
    "\n",
    "def mlp_actor_critic(x,a,hidden_sizes=(400,300),activation=tf.nn.relu,\n",
    "                     output_activation=tf.tanh,action_space=None):\n",
    "    act_dim=a.shape.as_list()[-1]\n",
    "    act_limit=action_space.high[0]\n",
    "    with tf.variable_scope('pi'):\n",
    "        pi=act_limit*mlp(x,list(hidden_sizes)+[act_dim],activation,output_activation)\n",
    "    with tf.variable_scope('q1'):\n",
    "        q1=tf.squeeze(mlp(tf.concat([x,a],axis=-1),list(hidden_sizes)+[1],activation,None),axis=1)\n",
    "    with tf.variable_scope('q2'):\n",
    "        q2=tf.squeeze(mlp(tf.concat([x,a],axis=-1),list(hidden_sizes)+[1],activation,None),axis=1)\n",
    "    with tf.variable_scope('q1',reuse=True):\n",
    "        q1_pi=tf.squeeze(mlp(tf.concat([x,pi],axis=-1),list(hidden_sizes)+[1],activation,None),axis=1)\n",
    "    return pi,q1,q2,q1_pi\n",
    "\n",
    "\n",
    "def get_vars(scope):\n",
    "    return [v for v in tf.global_variables() if scope in v.name]\n",
    "\n",
    "\n",
    "def count_vars(scope):\n",
    "    v=get_vars(scope)\n",
    "    return sum([np.prod(var.shape.as_list()) for var in v])\n",
    "        \n",
    "    \n",
    "\"\"\"\n",
    "main function\n",
    "\"\"\"\n",
    "def td3(env_fn,ac_kwargs=dict(),act_noise=0.1, target_noise=0.2, noise_clip=0.5,gamma=0.99,pi_lr=1e-3, \n",
    "        q_lr=1e-3, polyak=0.995,replay_size=int(1e6),steps_per_epoch=5000,epochs=100,start_steps=10000,\n",
    "        max_ep_len=1000,batch_size=100,policy_delay=2,logger_kwargs=dict()):\n",
    "\n",
    "    logger=EpochLogger(**logger_kwargs)\n",
    "    # 以dict保存在该行之前出现的局部变量（即参数列表中的超参数）和传入的logger_kwargs信息，并打印\n",
    "    logger.save_config(locals())\n",
    "    \n",
    "    tf.set_random_seed(0)\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    env,test_env=env_fn(),env_fn()\n",
    "    ac_kwargs['action_space']=env.action_space\n",
    "    obs_dim=env.observation_space.shape[0]\n",
    "    # 连续动作\n",
    "    act_dim=env.action_space.shape[0]\n",
    "    # 连续动作最大值\n",
    "    act_limit=env.action_space.high[0]\n",
    "    \n",
    "    \n",
    "    # input to computation graph\n",
    "    x_ph=tf.placeholder(tf.float32,[None,obs_dim])\n",
    "    a_ph=tf.placeholder(tf.float32,[None,act_dim])\n",
    "    x2_ph=tf.placeholder(tf.float32,[None,obs_dim])\n",
    "    r_ph=tf.placeholder(tf.float32,[None,])\n",
    "    d_ph=tf.placeholder(tf.float32,[None,])\n",
    "    \n",
    "    # main output from computation graph\n",
    "    with tf.variable_scope('main'):\n",
    "        pi,q1,q2,q1_pi=mlp_actor_critic(x_ph,a_ph,**ac_kwargs)\n",
    "    \n",
    "    # target policy net\n",
    "    with tf.variable_scope('target'):\n",
    "        pi_targ,_,_,_,=mlp_actor_critic(x2_ph,a_ph,**ac_kwargs)\n",
    "        \n",
    "    # target Q net\n",
    "    with tf.variable_scope('target',reuse=True):\n",
    "        epsilon=tf.random_normal(tf.shape(pi_targ),stddev=target_noise)\n",
    "        epsilon=tf.clip_by_value(epsilon,-noise_clip,noise_clip)\n",
    "        a2=pi_targ+epsilon\n",
    "        a2=tf.clip_by_value(a2,-act_limit,act_limit)\n",
    "        _,q1_targ,q2_targ,_=mlp_actor_critic(x2_ph,a2,**ac_kwargs)\n",
    "    \n",
    "    \n",
    "    # 需要在定义完网络马上计算，防止后面Adam对网络参数进行复制，重复计算\n",
    "    # print parameter number of each net\n",
    "    var_counts=tuple(count_vars(scope) for scope in ['main/pi','main/q1','main/q2','main'])\n",
    "    print('\\nNumber of parameters: pi %d, q1: %d, q2: %d, total: %d\\n'%var_counts)\n",
    "    \n",
    "    #Bellman backup for Q-learning\n",
    "    min_q_targ=tf.minimum(q1_targ,q2_targ)\n",
    "    backup=tf.stop_gradient(r_ph+gamma*(1-d_ph)*min_q_targ)\n",
    "    \n",
    "    # TD3 losses\n",
    "    pi_loss=-tf.reduce_mean(q1_pi)\n",
    "    q1_loss=tf.reduce_mean((q1-backup)**2)\n",
    "    q2_loss=tf.reduce_mean((q2-backup)**2)\n",
    "    q_loss=q1+q2\n",
    "    \n",
    "    # train ops for pi and q\n",
    "    pi_optimizer=tf.train.AdamOptimizer(learning_rate=pi_lr)\n",
    "    q_optimizer=tf.train.AdamOptimizer(learning_rate=q_lr)\n",
    "    train_pi_op=pi_optimizer.minimize(pi_loss,var_list=get_vars('main/pi'))\n",
    "    train_q_op=q_optimizer.minimize(q_loss,var_list=get_vars('main/q'))\n",
    "    \n",
    "    # Polyak averaging for target variables\n",
    "    target_update=tf.group([tf.assign(v_targ,polyak*v_targ+(1-polyak)*v_main) \n",
    "                            for v_main,v_targ in zip(get_vars('main'),get_vars('target'))])\n",
    "    \n",
    "    # initializing target variables to match the main\n",
    "    target_init=tf.group([tf.assign(v_targ,v_main) \n",
    "                          for v_main, v_targ in zip(get_vars('main'),get_vars('target'))])\n",
    "    \n",
    "    \n",
    "    sess=tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(target_init)\n",
    "    \n",
    "    # setup model saving\n",
    "    logger.setup_tf_saver(sess,inputs={'x':x_ph,'a':a_ph},outputs={'pi':pi,'q1':q1,'q2':q2})\n",
    "    \n",
    "    replay_buffer=ReplayBuffer(obs_dim,act_dim,replay_size)\n",
    "    \n",
    "    def get_action(o,act_noise=0):\n",
    "        a=sess.run(pi,feed_dict={x_ph:o.reshape(1,-1)})[0]\n",
    "        a+=act_noise*np.random.randn(act_dim)\n",
    "        return np.clip(a,-act_limit,act_limit)\n",
    "    \n",
    "    def test_agent(n=10):\n",
    "        for j in range(n):\n",
    "            o,r,d,ep_ret,ep_len=test_env.reset(),0,False,0,0\n",
    "            while not(d or (ep_len==max_ep_len)):\n",
    "                o,r,d,_=test_env.step(get_action(o))\n",
    "                ep_ret+=r\n",
    "                ep_len+=1\n",
    "            logger.store(TestEpRet=ep_ret,TestEpLen=ep_len)\n",
    "            \n",
    "    \n",
    "    start_time=time.time()\n",
    "    o,r,d,ep_ret,ep_len=env.reset(),0,False,0,0\n",
    "    total_steps=steps_per_epoch*epochs\n",
    "    for t in range(total_steps):\n",
    "        \n",
    "        if t>start_steps:\n",
    "            a=get_action(o,act_noise)\n",
    "        else:\n",
    "            a=env.action_space.sample()\n",
    "         \n",
    "        o2,r,d,_=env.step(a)\n",
    "        ep_ret+=r\n",
    "        ep_len+=1\n",
    "        \n",
    "        d=False if ep_len==max_ep_len else d\n",
    "        replay_buffer.store(o,a,r,o2,d)\n",
    "        o=o2\n",
    "        \n",
    "        # after each episode(trajectory) begin to train\n",
    "        if d or (ep_len==max_ep_len):\n",
    "            \n",
    "            for j in range(ep_len):\n",
    "                batch=replay_buffer.sample_batch(batch_size)\n",
    "                feed_dict={x_ph:batch['obs1'],\n",
    "                           a_ph:batch['acts'],\n",
    "                           r_ph:batch['rews'],\n",
    "                           x2_ph:batch['obs2'],\n",
    "                           d_ph:batch['done']}\n",
    "                \n",
    "                # Q nets update\n",
    "                q_step_ops=[q_loss,q1,q2,train_q_op]\n",
    "                outs=sess.run(q_step_ops,feed_dict)\n",
    "                logger.store(LossQ=outs[0],Q1Vals=outs[1],Q2Vals=outs[2])\n",
    "                \n",
    "                # delayed policy and all target nets update\n",
    "                if j%policy_delay==0:\n",
    "                    pi_step_ops=[pi_loss,train_pi_op,target_update]\n",
    "                    outs=sess.run(pi_step_ops,feed_dict)\n",
    "                    logger.store(LossPi=outs[0])\n",
    "                    \n",
    "            logger.store(EpRet=ep_ret,EpLen=ep_len)        \n",
    "            o, r, d, ep_ret, ep_len = env.reset(), 0, False, 0, 0\n",
    "            \n",
    "        # log after each epoch\n",
    "        if t>0 and t%steps_per_epoch==0:\n",
    "            epoch=t//steps_per_epoch\n",
    "            \n",
    "            # # Save model\n",
    "            # if (epoch % save_freq == 0) or (epoch == epochs-1):\n",
    "            #    logger.save_state({'env': env}, None)\n",
    "            \n",
    "            # test performance\n",
    "            test_agent()\n",
    "            \n",
    "            # log info about this epoch\n",
    "            logger.log_tabular('Epoch',epoch)\n",
    "            logger.log_tabular('EpRet',with_min_and_max=True)\n",
    "            logger.log_tabular('TestEpRet',with_min_and_max=True)\n",
    "            logger.log_tabular('EpLen',average_only=True)\n",
    "            logger.log_tabular('TestEpLen',average_only=True)\n",
    "            logger.log_tabular('TotalEnvInteracts',t)\n",
    "            logger.log_tabular('Q1Vals',with_min_and_max=True)\n",
    "            logger.log_tabular('Q2Vals',with_min_and_max=True)\n",
    "            logger.log_tabular('LossPi',average_only=True)\n",
    "            logger.log_tabular('LossQ',average_only=True)\n",
    "            logger.log_tabular('Time',time.time()-start_time)\n",
    "            logger.dump_tabular()\n",
    "            \n",
    "            \n",
    "            \n",
    "   \n",
    "tf.reset_default_graph()\n",
    "td3(lambda:gym.make('HalfCheetah-v2'),steps_per_epoch=5000,epochs=10,logger_kwargs=dict(exp_name='td3'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rl]",
   "language": "python",
   "name": "conda-env-rl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
